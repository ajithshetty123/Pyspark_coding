{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddbb09d5",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e8b572ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d566d858",
   "metadata": {},
   "source": [
    "### Create a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fac9bb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "        .appName(\"MySparkAppplication\")\\\n",
    "        .getOrCreate()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3586271a",
   "metadata": {},
   "source": [
    "### Read CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d992c1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Series_reference: string, Period: double, Data_value: double, Suppressed: string, STATUS: string, UNITS: string, Magnitude: int, Subject: string, Group: string, Series_title_1: string, Series_title_2: string, Series_title_3: string, Series_title_4: string, Series_title_5: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_path = 'C:\\\\Users\\\\ajith\\\\data_spark_operations\\\\file2.csv'\n",
    "\n",
    "df_csv = spark.read.format(\"csv\") \\\n",
    "        .option(\"header\",True) \\\n",
    "        .option(\"inferSchema\",\"true\") \\\n",
    "        .option(\"mode\",\"permissive\") \\\n",
    "        .load(csv_path)\n",
    "\n",
    "display(df_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafbb98e",
   "metadata": {},
   "source": [
    "### Read a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ca7cdfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+------+--------+----------+\n",
      "|age|firstName|gender|lastName|    number|\n",
      "+---+---------+------+--------+----------+\n",
      "| 28|      Joe|  male| Jackson|7349282382|\n",
      "| 32|    James|  male|   Smith|5678568567|\n",
      "| 24|    Emily|female|   Jones| 456754675|\n",
      "+---+---------+------+--------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "json_path = \"C:\\\\Users\\\\ajith\\\\data_spark_operations\\\\file1.json\"\n",
    "\n",
    "df_json = spark.read.format(\"json\") \\\n",
    "         .option(\"multiline\",True) \\\n",
    "         .option(\"mode\",\"DROPMALFORMED\") \\\n",
    "         .load(json_path)\n",
    "df_json =  df_json.selectExpr(\"explode(people) as person\").select(\"person.*\")\n",
    "\n",
    "df_json.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b35cd77",
   "metadata": {},
   "source": [
    "### Read a Parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "134563a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[PassengerId: bigint, Survived: bigint, Pclass: bigint, Name: string, Sex: string, Age: double, SibSp: bigint, Parch: bigint, Ticket: string, Fare: double, Cabin: string, Embarked: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parquet_path = \"C:\\\\Users\\\\ajith\\\\data_spark_operations\\\\file3.parquet\"\n",
    "\n",
    "df_parquet = spark.read.format(\"parquet\") \\\n",
    "             .load(parquet_path)\n",
    "\n",
    "display(df_parquet)\n",
    "\n",
    "df_parquet.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5635f39e",
   "metadata": {},
   "source": [
    "### Operations on Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bae6f6e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+--------------------+-----+\n",
      "| age|Todays date|          First name| Flag|\n",
      "+----+-----------+--------------------+-----+\n",
      "|80.0| 2025-03-10|Mr. Algernon Henr...|Major|\n",
      "|74.0| 2025-03-10|           Mr. Johan|Major|\n",
      "|71.0| 2025-03-10|           Mr. Ramon|Major|\n",
      "|71.0| 2025-03-10|        Mr. George B|Major|\n",
      "|70.5| 2025-03-10|         Mr. Patrick|Major|\n",
      "+----+-----------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter, WithColumn, If else(When)\n",
    "\n",
    "df_filter = df_parquet.filter(col(\"Sex\")==\"male\")\n",
    "df_withCol = df_parquet.withColumn(\"Todays date\",current_date()) \\\n",
    "                       .withColumn(\"First name\",trim(split(col(\"Name\"),\",\")[1])) \\\n",
    "                       .withColumn(\"age\",when(col(\"age\").isNull(),lit(10)).otherwise(col(\"age\"))) \\\n",
    "                       .withColumn(\"Flag\",when(col(\"age\")<25,\"Minor\").otherwise(\"Major\")) \\\n",
    "                       .select(\"age\",\"`Todays date`\",\"`First name`\",\"Flag\") \\\n",
    "                       .orderBy(col(\"age\").desc())\n",
    "\n",
    "df_withCol.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bfa250d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|   Sex|Cnt|\n",
      "+------+---+\n",
      "|  male|577|\n",
      "|female|314|\n",
      "+------+---+\n",
      "\n",
      "+-----+\n",
      "|  age|\n",
      "+-----+\n",
      "|28.34|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregate functions on dataframe\n",
    "# Count of male and female\n",
    "df_cnt = df_parquet.groupBy(\"Sex\").agg(count(\"PassengerId\").alias(\"Cnt\")).select(\"Sex\",\"Cnt\").orderBy(col(\"Sex\").desc())\n",
    "df_cnt.show()\n",
    "\n",
    "# Total avg age for survived passengers\n",
    "df_fare = df_parquet.filter(col(\"Survived\")==1).agg(round(avg(\"age\"),2).alias(\"age\")).select(\"*\")\n",
    "df_fare.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "41a6540f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+----+----------+\n",
      "|   Sex| Age|row_number|rank|dense_rank|\n",
      "+------+----+----------+----+----------+\n",
      "|  male|0.42|         1|   1|         1|\n",
      "|female|0.75|         1|   1|         1|\n",
      "|female|0.75|         2|   1|         1|\n",
      "|  male|0.67|         2|   2|         2|\n",
      "|female| 1.0|         3|   3|         2|\n",
      "+------+----+----------+----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Window functions\n",
    "window = Window.partitionBy(\"Sex\").orderBy(\"age\")\n",
    "\n",
    "df_window = df_parquet.withColumn(\"age\",when(col(\"age\").isNull(),lit(10)).otherwise(col(\"age\"))) \\\n",
    "                      .withColumn(\"row_number\",row_number().over(window)) \\\n",
    "                      .withColumn(\"rank\",rank().over(window)) \\\n",
    "                      .withColumn(\"dense_rank\",dense_rank().over(window)) \\\n",
    "                      .select(\"Sex\",\"Age\",\"row_number\",\"rank\",\"dense_rank\") \\\n",
    "                      .orderBy(col(\"row_number\").asc())\n",
    "\n",
    "df_window.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cbf8b7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+----------+----------+------+------+---------+--------------------+--------------------+--------------+--------------------+--------------+--------------+--------------+\n",
      "|Series_reference| Period|Data_value|Suppressed|STATUS| UNITS|Magnitude|             Subject|               Group|Series_title_1|      Series_title_2|Series_title_3|Series_title_4|Series_title_5|\n",
      "+----------------+-------+----------+----------+------+------+---------+--------------------+--------------------+--------------+--------------------+--------------+--------------+--------------+\n",
      "|     BDCQ.SEA1AA|2011.06|   80078.0|      null|     F|Number|        0|Business Data Col...|Industry by emplo...|   Filled jobs|Agriculture, Fore...|        Actual|          null|          null|\n",
      "|     BDCQ.SEA1AA|2011.09|   78324.0|      null|     F|Number|        0|Business Data Col...|Industry by emplo...|   Filled jobs|Agriculture, Fore...|        Actual|          null|          null|\n",
      "|     BDCQ.SEA1AA|2011.12|   85850.0|      null|     F|Number|        0|Business Data Col...|Industry by emplo...|   Filled jobs|Agriculture, Fore...|        Actual|          null|          null|\n",
      "|     BDCQ.SEA1AA|2012.03|   90743.0|      null|     F|Number|        0|Business Data Col...|Industry by emplo...|   Filled jobs|Agriculture, Fore...|        Actual|          null|          null|\n",
      "|     BDCQ.SEA1AA|2012.06|   81780.0|      null|     F|Number|        0|Business Data Col...|Industry by emplo...|   Filled jobs|Agriculture, Fore...|        Actual|          null|          null|\n",
      "+----------------+-------+----------+----------+------+------+---------+--------------------+--------------------+--------------+--------------------+--------------+--------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Joins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5d8e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write dataframe as  file\n",
    "\n",
    "df_parquet.coalesce(1).write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .format(\"csv\") \\\n",
    "        .save(\"C:\\\\Users\\\\ajith\\\\data_spark_operations\\\\parquet_file3.csv\")\n",
    "\n",
    "df_parquet.repartition(10).write \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .partitionBy(\"Sex\").format(\"parquet\") \\\n",
    "        .save(\"C:\\\\Users\\\\ajith\\\\data_spark_operations\\\\parquet_file3.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4362fdb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1607b7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
